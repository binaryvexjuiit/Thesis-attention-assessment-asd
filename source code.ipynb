{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only = False, min_cuda_compute_capability=None)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "gpu_available = tf.test.is_gpu_available()\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "is_cuda_gpu_min_3 = tf.test.is_gpu_available(True, (3,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.is_built_with_cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holistic model \n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Drawing Utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    #Color conversion\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #Image is no longer writable\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    \n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,76), thickness=8, circle_radius=8), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=8, circle_radius=4)\n",
    "                             ) \n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(23*3)\n",
    "    return pose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "\n",
    "os.chdir('D:\\Final Year Project\\Dataset')\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "# changing directory \n",
    "path = os.path.join(r'D:\\Final Year Project\\Dataset')\n",
    "\n",
    "#making directory for temporary data\n",
    "os.mkdir(os.path.join(r'D:\\Final Year Project\\TempExtractDataFP'))\n",
    "\n",
    "\n",
    "# iterating over multiple files \n",
    "for folder in (os.listdir(path)):\n",
    "    for file_num in range(len(os.listdir(folder))):\n",
    "        np.array(os.makedirs(os.path.join(r'D:\\Final Year Project\\TempExtractDataFP\\{folder}\\{file}').format(folder = folder, file = file_num + 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('D:\\Final Year Project\\Classified Data')\n",
    "os.getcwd()\n",
    "\n",
    "video_temp = os.path.join(r'D:\\Final Year Project\\Classified Data')\n",
    "\n",
    "for folder in (os.listdir(video_temp)):\n",
    "    #print(folder)\n",
    "    for file in (os.listdir(folder)):\n",
    "        #print(file)\n",
    "        cap = cv2.VideoCapture(os.path.join(video_temp, folder, file))\n",
    "        total_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if total_frame >= 160 :\n",
    "            print(folder, file)\n",
    "\n",
    "data_path = os.path.join(r'D:\\Final Year Project\\TempExtractDataFP')\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    print(folder)\n",
    "    for file in os.listdir(folder):\n",
    "        print(file)\n",
    "        frame_size = len(os.listdir(os.path.join(data_path, folder, file)))\n",
    "        desired_size = 154\n",
    "        if frame_size < desired_size:\n",
    "            new_frame = desired_size - frame_size\n",
    "            keypoints = np.zeros(1503)\n",
    "            for frame_index in range(1, new_frame + 1, 1):\n",
    "                npy_path = os.path.join(r'D:\\Final Year Project\\TempExtractDataFP\\{}\\{}\\{}').format(folder, file, frame_size + frame_index)\n",
    "                np.save(npy_path, keypoints)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video path\n",
    "video_temp = os.path.join(r'D:\\Final Year Project\\Dataset')\n",
    "\n",
    "# data path\n",
    "temp_data1 = os.path.join(r'D:\\Final Year Project\\ExtractData')\n",
    "\n",
    "for folder in (os.listdir(video_temp)):\n",
    "    file_num = 0\n",
    "    print(folder)\n",
    "    for file in os.listdir(os.path.join(video_temp, folder)):\n",
    "        file_num = file_num + 1\n",
    "        print(file)\n",
    "        \n",
    "        cap = cv2.VideoCapture(os.path.join(dataset, folder, file))\n",
    "        total_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        # set mediapipe model \n",
    "        with mp_holistic.Holistic(min_detection_confidence = 0.7, min_tracking_confidence = 0.5) as holistic:\n",
    "            for frame_index in range(1,total_frame,1):\n",
    "                \n",
    "                # read frame\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                # make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                \n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                # Export Keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                #print(keypoints.shape)\n",
    "                npy_path = os.path.join(r'D:\\Final Year Project\\ExtractData\\{folder}\\{file_num}\\{frame_index}').format(folder = folder, file_num = file_num, frame_index=frame_index)\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(['Highly Engaged', 'Moderate Engaged', 'Not Engaged', 'Undefined'])\n",
    "\n",
    "\n",
    "label_map = {label: num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    print(action)\n",
    "    for file in np.array(os.listdir(os.path.join(r'D:\\Final Year Project\\Data\\ExtractData\\{}').format(action))).astype(int):\n",
    "        print(file)\n",
    "        total_frame = 154\n",
    "        window = []\n",
    "        for frame_index in range(1,total_frame + 1,1):\n",
    "            result = np.load(os.path.join(r'D:\\Final Year Project\\Data\\ExtractData\\{}\\{}\\{}.npy').format(action, file,frame_index))\n",
    "            window.append(result)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(128, 3 ,activation='relu',input_shape = (154, 69)))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(tf.keras.layers.Conv1D(256, 3, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.40))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.50))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.50))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.50))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "history = model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "# Fit the model\n",
    "history = model.fit(X, Y, validation_split=0.25, epochs=100, batch_size = 64, verbose=1)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "ytrue = np.argmax(Y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "accuracy_score(ytrue, yhat)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(ytrue,model.predict(X_test), multi_class = 'ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn\n",
    "\n",
    "ax = seaborn.set(color_codes=True)\n",
    "plt.figure(1, figsize=(9, 6))\n",
    "#ax= plt.subplot()\n",
    "cm = confusion_matrix(ytrue, yhat)\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['0','1','2' '3']); ax.yaxis.set_ticklabels(['0', '1', '2', '3']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers(64, activation='relu', input_shape = (None, 10626)))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(tf.keras.layers(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(tf.keras.layers(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "history = model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "# Fit the model\n",
    "history = model.fit(X, Y, validation_split=0.25, epochs=100, batch_size = 64, verbose=1)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(64, 3 ,activation ='tanh',input_shape = (154, 99)))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(tf.keras.layers.Conv1D(128, 3, activation =\"tanh\"))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Conv1D(256, 3,activation='tanh'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "history = model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])\n",
    "# Fit the model\n",
    "history = model.fit(X, Y, validation_split=0.25, epochs=100, batch_size = 64, verbose=1)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"engagement.h5\")\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "ytrue = np.argmax(Y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "print(classification_report(ytrue, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(ytrue,model.predict(X_test), multi_class = 'ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0 : \"Highly Engaged\", 1 : \"Moderate Engaged\", 2: \"Not Engaged\", 3: \"Undefined\"}\n",
    "yhat = model.predict(X_test)\n",
    "predicted_label = np.argmax(yhat, axis=1).tolist()\n",
    "ytrue = np.argmax(Y_test, axis=1).tolist()\n",
    "\n",
    "for label, true_label in zip(predicted_label, range(true_labels)):\n",
    "    print(f\"the true label is {ytrue[true_label]} And The predicted engagement label is {labels[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = confusion_matrix(ytrue, yhat)\n",
    "plt.figure(1, figsize=(12, 9))\n",
    "DetaFrame_cm = pd.DataFrame(data, range(4), range(4))\n",
    "ax = seaborn.heatmap(DetaFrame_cm, annot=True, cmap='Greens_r',fmt='d', cbar=True, linewidths=3, linecolor='g', square=True, xticklabels=['Highly Engaged','Moderate Engaged','Not Engaged','Undefined'], yticklabels=['Highly Engaged','Moderate Engaged','Not Engaged','Undefined'])\n",
    "\n",
    "ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    " \n",
    "plt.savefig('confusion_matrix.png', bbox_inches='tight', dpi=600)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, activation='tanh', input_shape=(154, 99)))\n",
    "model.add(LSTM(512, return_sequences=True, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(LSTM(512, return_sequences=False, activation='tanh'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(actions.shape[0],activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "history = model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "# Fit the model\n",
    "history = model.fit(X, Y, validation_split=0.25, epochs=100, batch_size = 64, verbose=1)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "hist_csv_file = 'LSTM_history4.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = confusion_matrix(y_pred, ytrue)\n",
    "'''\n",
    "DetaFrame_cm = pd.DataFrame(data, range(4), range(4))\n",
    "seaborn.heatmap(DetaFrame_cm, annot=True)\n",
    "plt.show()\n",
    "'''\n",
    "plt.figure(1, figsize=(12, 9))\n",
    "DetaFrame_cm = pd.DataFrame(data, range(4), range(4))\n",
    "ax = seaborn.heatmap(DetaFrame_cm, annot=True, cmap='Greens_r',fmt='d', cbar=True, linewidths=3, linecolor='g', square=True, xticklabels=['Highly Engaged','Moderate Engaged','Not Engaged','Undefined'], yticklabels=['Highly Engaged','Moderate Engaged','Not Engaged','Undefined'])\n",
    "\n",
    "ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    " \n",
    "plt.savefig('confusion_matrix.png', bbox_inches='tight', dpi=600)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
